# -*- coding: utf-8 -*-
Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SyyoSlnan5WK_cs4hu8QS_iH_kfPKrWS
"""


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import precision_recall_fscore_support

df = pd.read_csv('/content/Career_Switch_Prediction_Dataset.csv')
df.head()

print(f"There are {df.shape[1]} features in the dataset")

print("Binary classification problem. Beacuse we are predicting two labels from the features")

print(f"There are {df.size} data points")

print(set(df.dtypes))                                                         #catagorical = object

len(df)

"""For the output feature, do all unique classes have an equal number of instances or not?

"""

df['will_change_career'].value_counts()

"""-Represent using a bar chart of N classes (N=number of classes you have in your dataset)."""

labels = ['will not chnage' ,'will change ']
values = [3738, 1262]

plt.bar(labels, values)
plt.xlabel("Labels")
plt.ylabel("Values")
plt.title("Class Distribution")
plt.show()

sns.countplot(x = 'will_change_career', data = df)
plt.title('Class Distribution')
plt.show()

cat_features = df.select_dtypes(include=['object']).columns
print("\nCategorical Features:", cat_features.tolist())

# Plot distribution of major categorical features
plt.figure(figsize=(14, 10))

for i, feature in enumerate(cat_features[:min(6, len(cat_features))]):
    plt.subplot(2, 3, i+1)

    if feature == 'city':
        # Plot only the top 10 most frequent cities
        top_cities = df['city'].value_counts().nlargest(10).index
        df[df['city'].isin(top_cities)]['city'].value_counts().plot(kind='bar')
        plt.title(f'Distribution of Top 10 {feature}')
        plt.xticks(rotation=45, ha='right')
    else:
        df[feature].value_counts().plot(kind='bar')
        plt.title(f'Distribution of {feature}')
        plt.xticks(rotation=45, ha='right')

plt.tight_layout()
plt.show()

# Explore numerical features
num_features = df.select_dtypes(include=['int64', 'float64']).columns
print("\nNumerical Features:", num_features.tolist())

# Plot distribution of major numerical features
plt.figure(figsize=(14, 10))
for i, feature in enumerate(num_features[:min(6, len(num_features))]):
    plt.subplot(2, 3, i+1)
    sns.histplot(df[feature], kde=True)
    plt.title(f'Distribution of {feature}')
plt.tight_layout()
plt.show()

"""**Correlation**"""

# # Assuming 'df' is your DataFrame
# for column in df.select_dtypes(include=['object']).columns:
#   df[column] = pd.factorize(df[column])[0]  # Use factorize for encoding
#        # Alternatively, use Label Encoding as mentioned in your code
#        # df[column] = LabelEncoder().fit_transform(df[column])

# numeric_df = df.select_dtypes(include=['int64', 'float64'])  # Update numeric_df
# plt.figure(figsize=(12, 10))
# correlation_matrix = numeric_df.corr()
# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5)
# plt.title('Correlation Matrix of Numerical Features')
# plt.show()

"""# **3**

# **dataset processing**
"""

#null vals and cat vals
print(df.isna().sum())

print("-----")

non_numeric_cols = df.select_dtypes(exclude='number').columns.tolist()
print(non_numeric_cols)

"""# **Dealing with null values**"""

len(df)

null_rows = df.isnull().any(axis=1).sum()
print(null_rows)

null_cols = df.columns[df.isna().any()].tolist()
print(null_cols)

for col in null_cols:
    if df[col].dtype == df['gender'].dtype: # datatype == categorical= mode
        mode = df[col].mode()[0]
        df[col] = df[col].fillna(mode)
    else :             # datatype == numeric = median
        df[col] = df[col].fillna(df[col].median())

df.isna().sum()

"""# **Dealing with cat values**"""

print(non_numeric_cols)

#Encoding
from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()

for cat_col in non_numeric_cols:
  df[cat_col] = le.fit_transform(df[cat_col])

df.dtypes

df['will_change_career'] = df['will_change_career'].astype('int64')

"""# **Feature Scalling**"""

for col in df.columns.to_list():
  col_var = np.var(df[col])                      #calculated variance ---> varivale gulor variance e onek diffrence thakle thn feature scalling kori
  print(f'{col}: {round(col_var,2)}')

y = [0,1]
std = np.std(y)         #standerd daviation
mean = np.mean(y)

print((0-mean)/std)
print((1-mean)/std)

features = df.drop('will_change_career',axis=1).columns.to_list()
print(features)

df.head()

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df[features] = scaler.fit_transform(df[features])
df.head()

for col in df.columns.to_list():
  col_var = np.var(df[col])
  print(f'{col}: {round(col_var,2)}')

"""# Dataset **Splitting**"""

df['will_change_career'].value_counts()

df_with_1 = df[df['will_change_career']==1]
df_with_0 = df[df['will_change_career']==0]

##class imbalancement            SMOTE-ing

reduce_samp_1 = df_with_1.sample(n=1262, replace=False)

df = pd.concat([reduce_samp_1,df_with_0])

df = df.sample(frac=1)  # shuffling df

df['will_change_career'].value_counts()

# Separate the classes
df_with_1 = df[df['will_change_career'] == 1]
df_with_0 = df[df['will_change_career'] == 0]

# Undersample the majority class (Class 0) to match the minority class (Class 1)
df_with_0_under = df_with_0.sample(n=1262, random_state=42, replace=False)

# Combine the balanced classes
df_balanced = pd.concat([df_with_1, df_with_0_under])

# Shuffle the combined dataset
df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)

# Verify the class distribution
print(df_balanced['will_change_career'].value_counts())

df.shape     #class imbalance

"""# **Test and Training**"""

from sklearn.model_selection import train_test_split
X = df.drop(columns=['will_change_career'])
y = df['will_change_career']
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state=1, stratify=y)

"""# **Modelling**"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score as acc

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay
from sklearn.metrics import accuracy_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import precision_recall_fscore_support


classifiers = [DecisionTreeClassifier(random_state=7), KNeighborsClassifier(), LogisticRegression(solver = 'lbfgs')]
# we use random_state for reproducibility, so that the model gives same prediction every time we run it
clf_accuracies = {}

for model in classifiers :
    model.fit(X_train,y_train)
    y_pred = model.predict(X_test)
    accuracy = acc(y_pred,y_test)

    clf_accuracies[type(model).__name__] = round(accuracy,2)

print(clf_accuracies)

"""# **Accuracy Comparison:**"""

# Model Selection/Comparison
labels = list(clf_accuracies.keys())
values = list(clf_accuracies.values())

plt.bar(labels, values)
plt.xlabel("Model")
plt.ylabel("Accuracy")
plt.title("Bar Chart of Model Accuracies")
plt.ylim(0, 1)  # Set y-axis limit to 1 for better visualization
plt.show()

from sklearn.metrics import confusion_matrix
from sklearn.metrics import precision_score, recall_score


classifiers = [DecisionTreeClassifier(random_state=7), KNeighborsClassifier(), LogisticRegression(solver = 'lbfgs')]


for model in classifiers :
    model.fit(X_train,y_train)
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_pred,y_test)

    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)

    print(f"{type(model).__name__}:")
    print(f"  Precision: {precision:.4f}")
    print(f"  Recall: {recall:.4f}")

    #print(type(model).__name__)
    #print(cm)
    print('-----------------')
    print('-----------------')

"""# **KNN Confusion Matrix:**"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder  # Import LabelEncoder


knn = KNeighborsClassifier()  # Initialize the KNN classifier
knn.fit(X_train, y_train)     # Train the KNN model on the training data
knn_pred = knn.predict(X_test) # Make predictions on the test set

knn_cm = confusion_matrix(y_test, knn_pred)

# Initialize LabelEncoder if it wasn't previously
label_encoder = LabelEncoder()
label_encoder.fit(y)  # Fit the encoder to your target variable (y)


disp = ConfusionMatrixDisplay(confusion_matrix=knn_cm, display_labels=label_encoder.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.xticks(rotation=90)
plt.title('Confusion Matrix for KNN')
plt.show()

"""# **Decision Tree Confusion Matrix:**"""

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(random_state=7)  # Initialize the Decision Tree classifier
dt.fit(X_train, y_train)     # Train the Decision Tree model on the training data
dt_pred = dt.predict(X_test) # Make predictions on the test set

dt_cm = confusion_matrix(y_test, dt_pred)

disp = ConfusionMatrixDisplay(confusion_matrix=knn_cm, display_labels=label_encoder.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.xticks(rotation=90)
plt.title('Confusion Matrix for Decision Tree')
plt.show()

"""# **Logistic Regression Confusion Matrix:**"""

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression(solver='lbfgs')  # Initialize the Logistic Regression classifier
lr.fit(X_train, y_train)     # Train the Logistic Regression model on the training data
lr_pred = lr.predict(X_test) # Make predictions on the test set


lr_cm = confusion_matrix(y_test, lr_pred)



disp = ConfusionMatrixDisplay(confusion_matrix=knn_cm, display_labels=label_encoder.classes_)
disp.plot(cmap=plt.cm.Blues)
plt.xticks(rotation=90)
plt.title('Confusion Matrix for Logistic Regression')
plt.show()

"""# **NN**"""

from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.callbacks import EarlyStopping
from keras.callbacks import ModelCheckpoint

from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

from tensorflow.keras.layers import Dropout
from tensorflow.keras.regularizers import l2
from tensorflow.keras.optimizers import Adam
# Build the neural network
input_dim = X_train.shape[1]  # Get the number of features from X_train
model = Sequential([
    Dense(64, activation='relu', input_shape=(input_dim,)),
    Dropout(0.2),
    Dense(32, activation='relu'),
    Dropout(0.2),
    Dense(1, activation='sigmoid')
])

# Compile the model
model.compile(optimizer='adam',
              loss='binary_crossentropy',
              metrics=['accuracy'])

print(model.summary())

# Define early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)



# Define early stopping
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

# Train the neural network with early stopping
# Assuming X_train is your original training data
from sklearn.preprocessing import StandardScaler  # Import StandardScaler

# Create a StandardScaler instance
scaler = StandardScaler()

# Fit the scaler on the training data and transform it
X_train_processed = scaler.fit_transform(X_train)

# Transform the test data using the fitted scaler
X_test_processed = scaler.transform(X_test)

# Compile the model with a different learning rate
optimizer = Adam(learning_rate=0.0005)  # Try a lower learning rate
model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])

history = model.fit(
    X_train_processed, y_train,
    epochs=50,
    batch_size=64,
    validation_split=0.2,
    callbacks=[early_stopping], # Include early stopping here
    verbose=2
)

# Evaluate the neural network
nn_accuracy = model.evaluate(X_test_processed, y_test)[1]
nn_pred_prob = model.predict(X_test_processed)
nn_pred = (nn_pred_prob > 0.5).astype(int).flatten()

# Calculate metrics for neural network
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix  # Import necessary metrics functions

nn_accuracy = accuracy_score(y_test, nn_pred)
nn_precision = precision_score(y_test, nn_pred)
nn_recall = recall_score(y_test, nn_pred)
nn_conf_matrix = confusion_matrix(y_test, nn_pred)

print("\nNeural Network Results:")
print(f"Accuracy: {nn_accuracy:.4f}")
print(f"Precision: {nn_precision:.4f}")
print(f"Recall: {nn_recall:.4f}")

# Plot loss curve
plt.plot(history.history['loss'])
plt.title("Loss Curve")
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.show()

# Print test error
print(f"Testing Accuracy: {round(model.evaluate(X_test_processed, y_test)[1] * 100, 2)}%") # Use processed test data

!pip install scikit-learn

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier


# Initialize a dictionary to store results
results = {}

# Calculate ROC curve and AUC for each model
for name, model in [('Logistic Regression', lr), ('KNN', knn), ('Decision Tree', dt), ('Neural Network', model)]:  # Include NN
    # Get predicted probabilities for class 1
    if name == 'Neural Network':
        y_pred_prob = model.predict(X_test_processed)  # For NN, use predict directly
    else:
        y_pred_prob = model.predict_proba(X_test)[:, 1]  # For others, use predict_proba

    # Calculate ROC curve
    fpr, tpr, _ = roc_curve(y_test, y_pred_prob)

    # Calculate AUC
    roc_auc = auc(fpr, tpr)

    # Store results
    results[name] = {'fpr': fpr, 'tpr': tpr, 'auc': roc_auc}

# Plot ROC curves
plt.figure(figsize=(10, 8))
for name, result in results.items():
    plt.plot(result['fpr'], result['tpr'], label=f"{name} (AUC = {result['auc']:.4f})")

plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve Comparison')
plt.legend(loc='best')
plt.show()

